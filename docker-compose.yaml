services:
  php:
    build:
      context: ./setup/php
    container_name: php-app
    volumes:
      - ./:/app
    working_dir: /app
    tty: true
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    # Uncomment the next line if you have Nvidia GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - capabilities: [gpu]
    volumes:
      - ollama:/root/.ollama
    ports:
      - "11434:11434"
    command: ["ollama", "api", "--host", "0.0.0.0", "--port", "11434"]
    restart: unless-stopped

volumes:
  ollama:
